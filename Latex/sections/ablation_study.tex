\section{Ablation Study}

We conduct a comprehensive ablation study to validate the individual contributions of our method's two key components: (1) \textbf{CACS} (Confusion-Calibrated Cross-Entropy), the client-side loss function that uses EMA-based confusion estimation, and (2) \textbf{FedSat}, the server-side class-specialized top-$p$ aggregation strategy. Results are reported on three benchmark datasets under severe label skew (Dirichlet $\beta{=}0.3$).

\subsection{Component-wise Analysis}

Table~\ref{tab:ablation-components} demonstrates the incremental gains from each component. Starting from the cross-entropy (CE) baseline, adding CACS provides substantial accuracy improvements across all datasets, validating the effectiveness of confusion-aware local training. Further adding FedSat's top-$p$ aggregation consistently enhances performance, demonstrating that server-side class prioritization complements client-side calibration.

\begin{table}[h]
\centering
\caption{Ablation study: Component-wise contribution. All experiments use Dirichlet $\beta{=}0.3$ with 100 clients. $\Delta$ shows absolute gain over baseline.}
\label{tab:ablation-components}
\begin{tabular}{lccc}
\toprule
\textbf{Configuration} & \textbf{CIFAR-10} & \textbf{FMNIST} & \textbf{CIFAR-100} \\
\midrule
Baseline (CE)          & 60.47\%           & 80.61\%         & 49.69\% \\
+ CACS                 & 71.41\% (\,$\Delta$+10.94)  & 84.39\% (\,$\Delta$+3.78)  & 50.91\% (\,$\Delta$+1.22) \\
+ CACS + FedSat        & \textbf{72.76\%} (\,$\Delta$+12.29)  & 83.92\% (\,$\Delta$+3.31)  & \textbf{51.29\%} (\,$\Delta$+1.60) \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Key observations:}
\begin{itemize}
    \item \textbf{CACS provides the largest gain} on CIFAR-10 (+10.94\%), significantly reducing class confusion under severe heterogeneity.
    \item \textbf{FedSat further improves} by +1.35\% on CIFAR-10, showing that server-side prioritization of struggling classes complements client-side calibration.
    \item On FMNIST, CACS alone achieves the highest accuracy (84.39\%), while FedSat maintains competitive performance. This suggests dataset-dependent sensitivity to aggregation strategies.
    \item On CIFAR-100 with its 100 classes, both components contribute incrementally, with the full method achieving 51.29\%.
\end{itemize}

\subsection{Top-$p$ Sensitivity Analysis}

To understand the sensitivity of FedSat to the top-$p$ selection parameter, we evaluate CIFAR-10 with varying values of $p$ (the number of classes prioritized during aggregation). Table~\ref{tab:ablation-topp} shows results with CACS as the base loss.

\begin{table}[h]
\centering
\caption{Ablation study: FedSat top-$p$ parameter sensitivity on CIFAR-10 ($\beta{=}0.3$, 100 clients). Base method uses CACS loss.}
\label{tab:ablation-topp}
\begin{tabular}{lcc}
\toprule
\textbf{Configuration} & \textbf{Top-$p$ Value} & \textbf{Accuracy} \\
\midrule
CACS (baseline)        & --                     & 71.41\% \\
\midrule
+ FedSat               & $p=1$                  & 73.38\% \\
+ FedSat               & $p=2$                  & \textbf{73.82\%} \\
+ FedSat               & $p=4$                  & 72.76\% \\
+ FedSat               & $p=5$                  & 73.37\% \\
+ FedSat               & $p=10$                 & 71.95\% \\
\bottomrule
\end{tabular}
\end{table}

\noindent\textbf{Analysis:}
\begin{itemize}
    \item \textbf{Optimal range:} $p \in \{1, 2, 4, 5\}$ consistently outperforms the CACS baseline, with peak performance at $p{=}2$ (73.82\%).
    \item \textbf{Too aggressive ($p{=}1$):} Focusing on only the single worst class still improves over baseline (+1.97\%), showing robustness.
    \item \textbf{Too conservative ($p{=}10$):} Selecting too many classes dilutes the prioritization effect, reducing gains to +0.54\%.
    \item \textbf{Sweet spot:} Values around $p{=}2\text{--}4$ balance between focusing on struggling classes and maintaining global model stability.
\end{itemize}

\subsection{Summary}

Our ablation study validates that:
\begin{enumerate}
    \item \textbf{CACS is the primary driver} of accuracy gains, particularly on datasets with high inter-class confusion (CIFAR-10).
    \item \textbf{FedSat provides consistent complementary gains} when properly tuned, with optimal top-$p$ values in the range of 2--4 for 10-class datasets.
    \item The two components are \textbf{orthogonal and complementary}: CACS addresses local training bias, while FedSat corrects global aggregation imbalance.
\end{enumerate}
