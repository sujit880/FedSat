#!/usr/bin/env python3
"""
Lightweight script to aggregate final accuracies from RESULTS/json_dump/*.json
and produce a LaTeX table for loss/aggregation ablation reporting.

Usage:
  python3 scripts/aggregate_results_for_table.py --out table.tex

The script uses filename tokens to infer method and dataset. Edit the
`METHOD_TOKENS` mapping below to match your experiment naming convention
if needed.
"""
import json
import glob
import os
import re
import argparse
from collections import defaultdict
import math


METHOD_TOKENS = {
    'CE': ['_L_CE_', '_L_CE', '_CE_','_ce_','_ce'],
    'CACS': ['_L_CACS_', 'cacs','CACS','_L_CACS'],
    'CALC': ['_L_CALC_', 'calc','CALC','_L_CALC'],
    'FedSat': ['fedsat','FedSat','fed_sat'],
    'FedSatC': ['fedsatc','fedsat_c','FedSatC'],
    'FedAvg': ['fedavg','FedAvg'],
    'FedProx': ['fedprox','FedProx'],
    'CCVR': ['ccvr','CCVR'],
    'Ditto': ['ditto','Ditto']
}

DATASETS = ['fmnist', 'femnist', 'cifar100', 'cifar', 'emnist']


def find_numeric_series(obj):
    """Recursively find numeric lists in JSON. Return list of numeric lists found."""
    out = []

    if isinstance(obj, list):
        # check if this list contains mostly numbers
        nums = [x for x in obj if isinstance(x, (int, float))]
        if len(nums) >= max(1, len(obj) // 2):
            out.append(nums)
        for v in obj:
            out.extend(find_numeric_series(v))
    elif isinstance(obj, dict):
        for v in obj.values():
            out.extend(find_numeric_series(v))
    return out


def guess_method(filename):
    low = filename.lower()
    for name, toks in METHOD_TOKENS.items():
        for t in toks:
            if t.lower() in low:
                return name
    return None


def guess_dataset(filename):
    low = filename.lower()
    for d in DATASETS:
        if d in low:
            # normalize 'cifar100' vs 'cifar'
            if d == 'cifar' and 'cifar100' in low:
                continue
            return d
    return None


def guess_alpha(filename):
    # map common patterns used in this repo (b0_05, b0_1, b0_3)
    if 'b0_05' in filename or 'b0-05' in filename:
        return '0.05'
    if 'b0_1' in filename or 'b0-1' in filename:
        return '0.1'
    if 'b0_3' in filename or 'b0-3' in filename:
        return '0.3'
    # fallback: try to find "b0[_-]?([0-9]+)"
    m = re.search(r'b0[_-]?([0-9]+)', filename)
    if m:
        v = m.group(1)
        try:
            val = float(v.replace('_', '.'))
            return str(val)
        except Exception:
            pass
    return 'unknown'


def final_value_from_json(path):
    try:
        with open(path, 'r') as f:
            obj = json.load(f)
    except Exception as e:
        print(f"WARN: could not read {path}: {e}")
        return None

    series = find_numeric_series(obj)
    if not series:
        print(f"WARN: no numeric series found in {path}")
        return None

    # choose longest series
    series.sort(key=lambda x: len(x), reverse=True)
    s = series[0]
    if not s:
        return None
    val = s[-1]
    # convert to percent if in [0,1]
    try:
        if 0 <= val <= 1:
            return float(val) * 100.0
        return float(val)
    except Exception:
        return None


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--results-dir', default='RESULTS/json_dump', help='path to json_dump')
    parser.add_argument('--out', default=None, help='output tex file (defaults to stdout)')
    args = parser.parse_args()

    files = glob.glob(os.path.join(args.results_dir, '*.json'))
    if not files:
        print('No JSON files found in', args.results_dir)
        return

    table = defaultdict(list)  # key: (method,dataset,alpha) -> list of vals

    for p in files:
        fn = os.path.basename(p)
        method = guess_method(fn)
        dataset = guess_dataset(fn)
        alpha = guess_alpha(fn)
        if method is None or dataset is None:
            # skip runs we can't categorize automatically
            # print a short warning so user can inspect
            print(f"SKIP (uncategorized): {fn} -> method={method} dataset={dataset}")
            continue
        val = final_value_from_json(p)
        if val is None or (isinstance(val, float) and math.isnan(val)):
            print(f"SKIP (no value): {fn}")
            continue
        key = (method, dataset, alpha)
        table[key].append(val)

    # produce a small LaTeX table by dataset and alpha
    datasets = sorted({k[1] for k in table.keys()})
    alphas = sorted({k[2] for k in table.keys()})
    methods = sorted({k[0] for k in table.keys()})

    out_lines = []
    out_lines.append('%% Auto-generated by scripts/aggregate_results_for_table.py')
    out_lines.append('\\begin{table*}[t]')
    out_lines.append('\\centering')
    out_lines.append('\\small')
    out_lines.append('\\begin{tabular}{l' + 'c' * (len(datasets) * max(1, len(alphas))) + '}')
    header = ['Method']
    for d in datasets:
        for a in alphas:
            header.append(f"{d} (a={a})")
    out_lines.append(' & '.join(header) + ' \\\\')
    out_lines.append('\\midrule')

    for m in methods:
        row = [m]
        for d in datasets:
            for a in alphas:
                vals = table.get((m, d, a), [])
                if not vals:
                    row.append('--')
                else:
                    mean = sum(vals) / len(vals)
                    # compute std
                    var = sum((x - mean) ** 2 for x in vals) / max(1, len(vals) - 1)
                    std = (var ** 0.5) if len(vals) > 1 else 0.0
                    row.append(f"{mean:.2f} $\pm$ {std:.2f}")
        out_lines.append(' & '.join(row) + ' \\\\')

    out_lines.append('\\bottomrule')
    out_lines.append('\\end{tabular}')
    out_lines.append('\\caption{Auto-aggregated accuracies (Top-1 \%).}')
    out_lines.append('\\end{table*}')

    out_text = '\n'.join(out_lines)
    if args.out:
        with open(args.out, 'w') as f:
            f.write(out_text)
        print('Wrote', args.out)
    else:
        print(out_text)


if __name__ == '__main__':
    main()
